{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "R2uPTZ4LOuyY"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import unicodedata\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>Loading and processing dataset</font>  \n",
    "    <font size = '2'>(based on PyTorch NLP tutorial i<sup>1</sup> and ii<sup>2</sup>)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "< : Start of string (SOS)\n",
    "> : End of string (EOS)\n",
    "# : PAD\n",
    "\"\"\"\n",
    "all_letters = \"#<>\" + string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [f'<{unicodeToAscii(line)}>' for line in lines]\n",
    "\n",
    "for filename in glob.glob('names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionaries w.r.t. letters\n",
    "letter2idx = {key: value for value, key in enumerate(all_letters)}\n",
    "idx2letter = {key: value for key, value in enumerate(all_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting names to tensors\n",
    "def name2tensor(name):\n",
    "    indices = []\n",
    "    for letter in name:\n",
    "        idx = letter2idx[letter]\n",
    "        indices.append(idx)\n",
    "    return torch.tensor(indices, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>Creating datasets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionaries w.r.t. categories\n",
    "lang2idx = {key: value for value, key in enumerate(all_categories)}\n",
    "idx2lang = {key: value for key, value in enumerate(all_categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for language in category_lines:\n",
    "    lang_idx = lang2idx[language]\n",
    "    for name in category_lines[language]:\n",
    "        all_data.append([name, language, lang_idx])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    all_data, columns=['Name', 'Language', 'Language index']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of duplicates\n",
    "int(df.Name.duplicated().value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset with dict output structure\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.df.iloc[idx]\n",
    "        name = entry[0]\n",
    "        name_tensor = name2tensor(name)\n",
    "        language = entry[1]\n",
    "        language_index = entry[2]\n",
    "        return {'Name':name, 'Name tensor':name_tensor, \n",
    "                'Language':language, 'Language index':language_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': '<Bastl>',\n",
       " 'Name tensor': tensor([ 1, 30,  3, 21, 22, 14,  2], dtype=torch.int32),\n",
       " 'Language': 'Czech',\n",
       " 'Language index': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = NamesDataset(df)\n",
    "dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>Creating dataloaders with custom collate_fn</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NamesDataset(train)\n",
    "val_dataset = NamesDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    names = []\n",
    "    name_tensors = []\n",
    "    languages = []\n",
    "    language_indices = []\n",
    "    for item in batch:\n",
    "        names.append(item['Name'])\n",
    "        name_tensors.append(item['Name tensor'])\n",
    "        languages.append(item['Language'])\n",
    "        language_indices.append(item['Language index'])\n",
    "\n",
    "    name_tensors = pad_sequence(name_tensors, batch_first=True)\n",
    "    language_indices = torch.tensor(language_indices)\n",
    "\n",
    "    return names, name_tensors, languages, language_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4],\n",
       "        [0, 8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a test of pad_sequence\n",
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4, 8])\n",
    "c = [a, b]\n",
    "pad_sequence(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                               shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, \n",
    "                                             shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<Libusov>',\n",
       "  '<Handal>',\n",
       "  '<Whyte>',\n",
       "  '<Gayazov>',\n",
       "  '<Simon>',\n",
       "  '<Nazari>',\n",
       "  '<Islanov>',\n",
       "  '<Balabuha>',\n",
       "  '<Eizen>',\n",
       "  '<Pokhitonov>',\n",
       "  '<Seer>',\n",
       "  '<Xie>',\n",
       "  '<Cullen>',\n",
       "  '<Mikhaleiko>',\n",
       "  '<Antar>',\n",
       "  '<Bruhn>',\n",
       "  '<Barros>',\n",
       "  '<Kitson>',\n",
       "  '<Jarrett>',\n",
       "  '<Shening>',\n",
       "  '<Finkelshtein>',\n",
       "  '<Minkin>',\n",
       "  '<Zhiharevitch>',\n",
       "  '<Clay>',\n",
       "  '<Chalykh>',\n",
       "  '<Chuvashev>',\n",
       "  '<Baron>',\n",
       "  '<Zogby>',\n",
       "  '<Shamoon>',\n",
       "  '<Jakuba>',\n",
       "  '<Mniszech>',\n",
       "  '<Almasi>'],\n",
       " tensor([[ 1, 40, 11,  4, 23, 21, 17, 24,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 36,  3, 16,  6,  3, 14,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 51, 10, 27, 22,  7,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 35,  3, 27,  3, 28, 17, 24,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 47, 11, 15, 17, 16,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 42,  3, 28,  3, 20, 11,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 37, 21, 14,  3, 16, 17, 24,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 30,  3, 14,  3,  4, 23, 10,  3,  2,  0,  0,  0,  0],\n",
       "         [ 1, 33, 11, 28,  7, 16,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 44, 17, 13, 10, 11, 22, 17, 16, 17, 24,  2,  0,  0],\n",
       "         [ 1, 47,  7,  7, 20,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 52, 11,  7,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 31, 23, 14, 14,  7, 16,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 41, 11, 13, 10,  3, 14,  7, 11, 13, 17,  2,  0,  0],\n",
       "         [ 1, 29, 16, 22,  3, 20,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 30, 20, 23, 10, 16,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 30,  3, 20, 20, 17, 21,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 39, 11, 22, 21, 17, 16,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 38,  3, 20, 20,  7, 22, 22,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 47, 10,  7, 16, 11, 16,  9,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 34, 11, 16, 13,  7, 14, 21, 10, 22,  7, 11, 16,  2],\n",
       "         [ 1, 41, 11, 16, 13, 11, 16,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 54, 10, 11, 10,  3, 20,  7, 24, 11, 22,  5, 10,  2],\n",
       "         [ 1, 31, 14,  3, 27,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 31, 10,  3, 14, 27, 13, 10,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 31, 10, 23, 24,  3, 21, 10,  7, 24,  2,  0,  0,  0],\n",
       "         [ 1, 30,  3, 20, 17, 16,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 54, 17,  9,  4, 27,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 47, 10,  3, 15, 17, 17, 16,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 38,  3, 13, 23,  4,  3,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 1, 41, 16, 11, 21, 28,  7,  5, 10,  2,  0,  0,  0,  0],\n",
       "         [ 1, 29, 14, 15,  3, 21, 11,  2,  0,  0,  0,  0,  0,  0]],\n",
       "        dtype=torch.int32),\n",
       " ['Russian',\n",
       "  'Arabic',\n",
       "  'Scottish',\n",
       "  'Russian',\n",
       "  'English',\n",
       "  'Arabic',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'English',\n",
       "  'Chinese',\n",
       "  'English',\n",
       "  'Russian',\n",
       "  'Arabic',\n",
       "  'German',\n",
       "  'Portuguese',\n",
       "  'English',\n",
       "  'English',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'English',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'English',\n",
       "  'Arabic',\n",
       "  'Arabic',\n",
       "  'Russian',\n",
       "  'Russian',\n",
       "  'Arabic'],\n",
       " tensor([ 6,  2, 14,  6,  9,  2,  6,  6,  6,  6,  9,  4,  9,  6,  2,  1, 13,  9,\n",
       "          9,  6,  6,  6,  6,  9,  6,  6,  9,  2,  2,  6,  6,  2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>Attention layer (custom implementation)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, method):\n",
    "        super().__init__()\n",
    "        assert method in ['dot', 'general', 'concat']\n",
    "        \n",
    "        self.hidden_projector = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        \n",
    "        self.method = method\n",
    "        if self.method == 'general':\n",
    "            self.linear_gen = nn.Linear(hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.linear_cat_1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "            self.linear_cat_2 = nn.Linear(hidden_size, 1)\n",
    "            \n",
    "        \n",
    "    def forward(self, rnn_outputs, rnn_final_hidden):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        [\\bar{h}_s]     rnn_outputs           shape: (batch_size, sequence_length, hidden_size)\n",
    "        [h_t]           rnn_final_hidden      shape: (batch_size, hidden_size)\n",
    "        \n",
    "        OUTPUT:\n",
    "        [\\hat{h}_t]     attention_output      shape: (batch_size, hidden_size)\n",
    "        [\\alpha_t(s)]   attention_weights     shape: (batch_size, sequence_length)\n",
    "        \"\"\"\n",
    "        if self.method == 'dot':\n",
    "            att_score = torch.bmm(rnn_outputs, rnn_final_hidden.unsqueeze(dim=2)).squeeze() #(N x L)\n",
    "        elif self.method == 'general':\n",
    "            #att_score = torch.bmm(rnn_outputs, self.linear_gen(rnn_final_hidden).unsqueeze(dim=2)).squeeze()\n",
    "            att_score = torch.bmm(self.linear_gen(rnn_outputs), rnn_final_hidden.unsqueeze(dim=2)).squeeze()\n",
    "        elif self.method == 'concat':\n",
    "            hidden_cat = torch.cat((rnn_outputs, rnn_final_hidden.unsqueeze(1).expand(rnn_outputs.shape)), dim=2)\n",
    "            att_embed = torch.tanh(self.linear_cat_1(hidden_cat))\n",
    "            att_score = self.linear_cat_2(att_embed).squeeze()\n",
    "            \n",
    "        attention_weights = F.softmax(att_score, dim=1) #(N x L)\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(dim=1), rnn_outputs).squeeze()\n",
    "        attention_output = torch.tanh(self.hidden_projector(torch.cat((context_vector, rnn_final_hidden), dim=1)))\n",
    "        \n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pR0Ag0nOuya"
   },
   "source": [
    "<font size='4'>LSTM classifier with trainable embedding and attention</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        embedding_dim = 20\n",
    "        #c_out = 25\n",
    "        hidden_dim = 30\n",
    "        self.char_embedding = nn.Embedding(len(all_letters), embedding_dim, \n",
    "                                          padding_idx=0)\n",
    "        #self.conv = nn.Conv1d(20, c_out, kernel_size=3, padding=1) #(N, L, 20) optional conv layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, len(all_categories))\n",
    "        self.attention_layer = AttentionLayer(hidden_dim * 2, 'general')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.char_embedding(x) #(N, L, 20)\n",
    "        #x = self.conv(x) #(N, L, 25) optional conv\n",
    "        lstm_output = self.lstm(x)\n",
    "        rnn_outputs = lstm_output[0]\n",
    "        rnn_final_hidden = lstm_output[1][0] #(N, 2, 30) ('2' for bidirectional case)\n",
    "        rnn_final_hidden = rnn_final_hidden.permute(1, 0, -1)\n",
    "        rnn_final_hidden = torch.cat((torch.chunk(rnn_final_hidden, 2, dim=1)[0], \n",
    "                                      torch.chunk(rnn_final_hidden, 2, dim=1)[1]), dim=2)\n",
    "        rnn_final_hidden = rnn_final_hidden.squeeze()\n",
    "        x = self.attention_layer(rnn_outputs, rnn_final_hidden)[0]\n",
    "        x = self.linear(x)\n",
    "        scores = F.log_softmax(x, dim=1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 60])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the cat function\n",
    "cat_sample = torch.randn(32, 2, 30)\n",
    "torch.cat((torch.chunk(cat_sample, 2, dim=1)[0], torch.chunk(cat_sample, 2, dim=1)[1]), dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 14])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if everything is fine dimension-wise\n",
    "next(iter(train_dataloader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 18])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTMClassifier()\n",
    "lstm(next(iter(train_dataloader))[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 14])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing applying conv\n",
    "test_conv = nn.Conv1d(1, 20, kernel_size=3)\n",
    "test_seq_batch = torch.randn(32, 1, 16)\n",
    "test_conv(test_seq_batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lamfPnUaOuyd"
   },
   "source": [
    "<font size='4'>Training with PL and Tensorboard viz</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #defines prediction/inference actions\n",
    "        return torch.exp(self.model(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):      \n",
    "        x, y = batch[1], batch[3]\n",
    "        neg_logs = self.model(x)\n",
    "        loss = loss_fn(neg_logs, y)\n",
    "        probs = torch.exp(neg_logs)\n",
    "        train_accuracy = self.train_accuracy(probs, y)\n",
    "        \n",
    "        # logging to tensorboard\n",
    "        self.log(\"train loss\", loss, prog_bar=True)\n",
    "        self.log(\"train acc\", train_accuracy, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):   \n",
    "        x, y = batch[1], batch[3]\n",
    "        neg_logs = self.model(x)\n",
    "        loss = loss_fn(neg_logs, y)\n",
    "        probs = torch.exp(neg_logs)\n",
    "        self.val_accuracy(probs, y)\n",
    "        \n",
    "        #logging to tensorboard\n",
    "        self.log(\"val loss\", loss, prog_bar=True)\n",
    "        self.log(\"val acc\", self.val_accuracy, prog_bar=True)\n",
    "        \n",
    "    def training_epoch_end(self, *args, **kwargs):\n",
    "        self.train_accuracy.reset()\n",
    "        \n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log('val acc', self.val_accuracy.compute(), prog_bar=True)\n",
    "        self.val_accuracy.reset()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier()\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "pl_model = PLModel(model)\n",
    "logger = TensorBoardLogger('lstm_logs', default_hp_metric=False) \n",
    "trainer = pl.Trainer(max_epochs=10, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-55fab13e2f9962f1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-55fab13e2f9962f1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lstm_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lstm_logs/default\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | model          | LSTMClassifier | 25.7 K\n",
      "1 | train_accuracy | Accuracy       | 0     \n",
      "2 | val_accuracy   | Accuracy       | 0     \n",
      "--------------------------------------------------\n",
      "25.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.7 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:372: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfe721fc990405e935c99cc90b811d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pl_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val acc': 0.8049813508987427, 'val loss': 0.7084192037582397}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val loss': 0.7084192037582397, 'val acc': 0.8049813508987427}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation run\n",
    "trainer.validate(pl_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sup>1</sup>https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html  \n",
    "<sup>2</sup>https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "char_rnn_classification_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
